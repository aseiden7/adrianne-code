---
title: "Investigating Factors Effecting CO₂ Flux from Pots"
author: "Adrianne Seiden"
date: "`r Sys.Date()`"
output:
  html_document:
    self_contained: true
    toc: true
    toc_float: true
    toc_depth: 2
    theme: darkly
    highlight: zenburn
    code_folding: hide
---
```{r setup, include=FALSE}
library(reticulate)

# Configure Python installation
# Mac install
use_python("/Users/adrianneseiden/Library/Caches/org.R-project.R/R/reticulate/uv/cache/archive-v0/4R66RK1qjSkCbDYQUxbIy/bin/python3") #nolint

# # Windows install
# use_python("C:/Users/adria/AppData/Local/Programs/Python/Python313/python.exe") #nolint

knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  comment = ">",
  results = 'hold'
)
```
# Introduction
CO₂ flux data from the pots differs significantly from the jars. This could be due to more fluctuating moisture levels, inconsistency in time sealed, or something else. Since we have data on moisture levels, and the time sealed, we can investigate these factors to see if they explain the differences in flux more than the crop types.

In particular, the time over which the week 10 flux was collected varies significantly between the crops. Rice pots were only sealed an average of 25.33 minutes, compared to 45 minutes for wheat and 60 minutes for soy. By comparison, week 20 flux measurements were collected over 61 minutes (standard deviation <1 minute; no rice fluxes), week 30 was collected over 78 minutes (standard deviation 13 minutes), and week 40 was collected over 100 minutes (standard deviation 13 minutes). See "Box/Salk Institute Project/AKS Salk files/CO2 data/combined_data_with_moisture.xlsx" for more detail.

# CO2 Flux Analysis: Moisture vs Time vs Crop Effects (Controlling for Sampling Week)

## Setup and Data Loading

```{python setup-load-data}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

# Set matplotlib parameters for better display in R Markdown
plt.rcParams['figure.figsize'] = (12, 8)
plt.rcParams['font.size'] = 10

def load_and_analyze_flux_data(file_path):
    """Load data and perform comprehensive analysis of CO2 flux relationships"""
    print("Loading data...")
    df = pd.read_excel(file_path)
    
    # Find the flux column
    flux_col = None
    for col in df.columns:
        if 'flux' in col.lower() and 'co2' in col.lower():
            flux_col = col
            break
    
    if flux_col is None:
        print("Available columns:")
        print(df.columns.tolist())
        return None, None
    
    # Modified cleaning: require flux, sealed_minutes, and sampling_wk, but allow missing moisture
    essential_cols = [flux_col, 'sealed_minutes', 'sampling_wk']
    df_clean = df.dropna(subset=essential_cols)
    
    print(f"Data loaded: {len(df_clean)} valid observations")
    print(f"Flux column: {flux_col}")
    print(f"Sampling weeks range: {df_clean['sampling_wk'].min()} to {df_clean['sampling_wk'].max()}")
    
    # Report on moisture data availability
    moisture_missing = df_clean['moisture_kpa'].isna().sum()
    moisture_available = len(df_clean) - moisture_missing
    print(f"Moisture data: {moisture_available} available, {moisture_missing} missing ({moisture_missing/len(df_clean)*100:.1f}%)")
    
    if moisture_missing > 0:
        print("Missing moisture data by week:")
        missing_by_week = df_clean[df_clean['moisture_kpa'].isna()].groupby(['sampling_wk', 'crop']).size()
        for (week, crop), count in missing_by_week.items():
            print(f"  Week {week}, {crop}: {count} observations")
    
    return df_clean, flux_col

# Path to Excel file from local repository
import os
box_base = os.environ.get('BOX_BASE')
if box_base is None:
    raise ValueError("BOX_BASE environment variable is not set!")

file_path = os.path.join(box_base, "Salk Institute Project/AKS Salk files/CO2 data/combined_data_with_moisture.xlsx")
output_folder = os.path.join(box_base, "Salk Institute Project/AKS Salk files/CO2 data/confounding-factors-outputs")
# # Load the data
# file_path = "combined_data_with_moisture.xlsx"  # Update this path as needed
df, flux_col = load_and_analyze_flux_data(file_path)

# Investigate missing data at week 20 and week 29
print("\nINVESTIGATING MISSING DATA:")
print("="*50)

# Check what sampling weeks we have
print("Available sampling weeks:")
print(sorted(df['sampling_wk'].unique()))

# Check data availability by week and crop
print("\nData availability by week and crop:")
availability = df.groupby(['sampling_wk', 'crop']).size().reset_index(name='count')
availability_pivot = availability.pivot(index='sampling_wk', columns='crop', values='count').fillna(0)
print(availability_pivot)

# Check specifically for problematic weeks
problem_weeks = [20, 29]
for week in problem_weeks:
    week_data = df[df['sampling_wk'] == week]
    print(f"\n--- WEEK {week} ANALYSIS ---")
    if len(week_data) > 0:
        print(f"Week {week} data found: {len(week_data)} observations")
        print(f"Week {week} data by crop:")
        print(week_data['crop'].value_counts())
        
        # Check for missing values in key columns
        print(f"\nWeek {week} missing values check:")
        key_cols = [flux_col, 'moisture_kpa', 'sealed_minutes', 'sampling_wk']
        for col in key_cols:
            if col in week_data.columns:
                missing = week_data[col].isna().sum()
                print(f"  {col}: {missing} missing values")
            else:
                print(f"  {col}: column not found!")
    else:
        print(f"No data found for week {week} in cleaned dataset!")
        
        # Check the original data before cleaning
        print(f"Checking original data for week {week}...")
        import pandas as pd
        df_original = pd.read_excel(file_path)
        if 'sampling_wk' in df_original.columns:
            week_original = df_original[df_original['sampling_wk'] == week]
            print(f"  Week {week} in original data: {len(week_original)} rows")
            if len(week_original) > 0:
                print(f"  Week {week} crops in original data:")
                print(week_original['crop'].value_counts())
                
                # Check what columns have missing values in the original week data
                key_cols_original = []
                for col in df_original.columns:
                    if 'flux' in col.lower() and 'co2' in col.lower():
                        key_cols_original.append(col)
                        break
                key_cols_original.extend(['moisture_kpa', 'sealed_minutes'])
                
                print(f"  Missing values in original week {week} data:")
                for col in key_cols_original:
                    if col in week_original.columns:
                        missing = week_original[col].isna().sum()
                        total = len(week_original)
                        print(f"    {col}: {missing}/{total} missing ({missing/total*100:.1f}%)")
        else:
            print(f"  No 'sampling_wk' column found in original data")

# Additional analysis: show the full data cleaning process
print(f"\n--- DATA CLEANING ANALYSIS ---")
df_original = pd.read_excel(file_path)
print(f"Original data size: {len(df_original)} rows")

# Find flux column in original data
flux_col_original = None
for col in df_original.columns:
    if 'flux' in col.lower() and 'co2' in col.lower():
        flux_col_original = col
        break

if flux_col_original:
    print(f"Flux column found: '{flux_col_original}'")
    required_cols = [flux_col_original, 'moisture_kpa', 'sealed_minutes', 'sampling_wk']
    
    # Check each required column
    print("\nRequired columns analysis:")
    for col in required_cols:
        if col in df_original.columns:
            missing = df_original[col].isna().sum()
            total = len(df_original)
            print(f"  {col}: {missing}/{total} missing ({missing/total*100:.1f}%)")
        else:
            print(f"  {col}: COLUMN NOT FOUND!")
    
    # Show data loss by week
    print("\nData loss by sampling week:")
    for week in sorted(df_original['sampling_wk'].unique()):
        week_before = len(df_original[df_original['sampling_wk'] == week])
        df_week_clean = df_original[df_original['sampling_wk'] == week].dropna(subset=required_cols)
        week_after = len(df_week_clean)
        loss = week_before - week_after
        if loss > 0:
            print(f"  Week {week}: {week_before} → {week_after} (lost {loss} rows, {loss/week_before*100:.1f}%)")
else:
    print("No flux column found in original data!")
    print("Available columns:")
    print(df_original.columns.tolist())
```

## Confounding Analysis

```{python confounding}
def analyze_confounding(df, flux_col):
    """Analyze the confounding relationships between variables"""
    print("=" * 60)
    print("CONFOUNDING ANALYSIS")
    print("=" * 60)
    
    # Check correlation between sealed_time and sampling_wk
    time_wk_corr = np.corrcoef(df['sealed_minutes'], df['sampling_wk'])[0,1]
    print(f"Correlation between sealed_time and sampling_wk: r = {time_wk_corr:.3f}")
    
    # Check correlation between flux and sampling_wk
    flux_wk_corr = np.corrcoef(df[flux_col], df['sampling_wk'])[0,1]
    print(f"Correlation between flux and sampling_wk: r = {flux_wk_corr:.3f}")
    
    # Check correlation between moisture and sampling_wk
    moisture_wk_corr = np.corrcoef(df['moisture_kpa'], df['sampling_wk'])[0,1]
    print(f"Correlation between moisture and sampling_wk: r = {moisture_wk_corr:.3f}")
    
    if abs(time_wk_corr) > 0.3:
        print("\n⚠️  WARNING: Strong correlation between sealed_time and sampling_wk!")
        print("   This could lead to confounded results for sealed_time effects.")
    
    if abs(flux_wk_corr) > 0.3:
        print("\n📉 Strong temporal trend in flux over sampling weeks")
        if flux_wk_corr < 0:
            print("   Flux decreases over time (as expected)")
        else:
            print("   Flux increases over time (unexpected)")
    
    return {
        'time_wk_corr': time_wk_corr,
        'flux_wk_corr': flux_wk_corr,
        'moisture_wk_corr': moisture_wk_corr
    }

# Analyze confounding relationships
confounding_stats = analyze_confounding(df, flux_col)
```

## Advanced Statistical Analysis Functions

```{python advanced-stats}
def calculate_r2(y_actual, y_predicted):
    """Calculate R-squared manually"""
    ss_res = np.sum((y_actual - y_predicted) ** 2)
    ss_tot = np.sum((y_actual - np.mean(y_actual)) ** 2)
    return 1 - (ss_res / ss_tot) if ss_tot != 0 else 0

def simple_linear_regression(x, y):
    """Simple linear regression without sklearn"""
    x = np.array(x)
    y = np.array(y)
    n = len(x)
    
    # Calculate slope and intercept
    slope = (n * np.sum(x * y) - np.sum(x) * np.sum(y)) / (n * np.sum(x**2) - (np.sum(x))**2)
    intercept = (np.sum(y) - slope * np.sum(x)) / n
    
    # Calculate predictions and R²
    y_pred = slope * x + intercept
    r2 = calculate_r2(y, y_pred)
    
    return slope, intercept, r2, y_pred

def partial_correlation(x, y, z):
    """Calculate partial correlation between x and y controlling for z"""
    # Simple partial correlation calculation
    rxy = np.corrcoef(x, y)[0,1]
    rxz = np.corrcoef(x, z)[0,1] 
    ryz = np.corrcoef(y, z)[0,1]
    
    numerator = rxy - (rxz * ryz)
    denominator = np.sqrt((1 - rxz**2) * (1 - ryz**2))
    
    if abs(denominator) < 1e-10:
        return 0
    
    return numerator / denominator

def residual_regression(x, y, control_vars):
    """Regression of y on x after removing effects of control variables"""
    # Remove control variable effects from y
    y_residual = y.copy()
    for control in control_vars:
        slope, intercept, _, y_pred = simple_linear_regression(control, y_residual)
        y_residual = y_residual - (slope * control + intercept - np.mean(y_residual))
    
    # Remove control variable effects from x  
    x_residual = x.copy()
    for control in control_vars:
        slope, intercept, _, x_pred = simple_linear_regression(control, x_residual)
        x_residual = x_residual - (slope * control + intercept - np.mean(x_residual))
    
    # Regression of residuals
    slope, intercept, r2, y_pred = simple_linear_regression(x_residual, y_residual)
    
    return slope, intercept, r2, np.corrcoef(x_residual, y_residual)[0,1]

def calculate_controlled_effects(df, flux_col):
    """Calculate effect sizes controlling for sampling week (handling missing moisture data)"""
    effects = {}
    
    # Separate data with and without moisture
    moisture_data = df[['moisture_kpa', flux_col, 'sampling_wk']].dropna()
    time_data = df[['sealed_minutes', flux_col, 'sampling_wk']].dropna()
    
    print(f"Calculating effects with:")
    print(f"  Moisture analysis: {len(moisture_data)} observations")
    print(f"  Time analysis: {len(time_data)} observations")
    
    if len(moisture_data) > 1:
        # Original moisture effect
        x = moisture_data['moisture_kpa'].values
        y = moisture_data[flux_col].values
        slope, intercept, r2, y_pred = simple_linear_regression(x, y)
        effects['moisture_r2_raw'] = r2
        effects['moisture_corr_raw'] = np.corrcoef(x, y)[0,1]
        
        # Controlled moisture effect (controlling for sampling week)
        z = moisture_data['sampling_wk'].values
        partial_corr = partial_correlation(x, y, z)
        effects['moisture_corr_controlled'] = partial_corr
        effects['moisture_r2_controlled'] = partial_corr**2
        
        # Residual regression approach
        slope_res, intercept_res, r2_res, corr_res = residual_regression(x, y, [z])
        effects['moisture_r2_residual'] = r2_res
        effects['moisture_slope_controlled'] = slope_res
    else:
        print("Warning: Insufficient data for moisture analysis")
        effects['moisture_r2_raw'] = 0
        effects['moisture_corr_raw'] = 0
        effects['moisture_corr_controlled'] = 0
        effects['moisture_r2_controlled'] = 0
        effects['moisture_slope_controlled'] = 0
    
    if len(time_data) > 1:
        # Original sealed time effect
        x = time_data['sealed_minutes'].values
        y = time_data[flux_col].values
        slope, intercept, r2, y_pred = simple_linear_regression(x, y)
        effects['time_r2_raw'] = r2
        effects['time_corr_raw'] = np.corrcoef(x, y)[0,1]
        
        # Controlled time effect (controlling for sampling week)
        z = time_data['sampling_wk'].values
        partial_corr = partial_correlation(x, y, z)
        effects['time_corr_controlled'] = partial_corr
        effects['time_r2_controlled'] = partial_corr**2
        
        # Residual regression approach
        slope_res, intercept_res, r2_res, corr_res = residual_regression(x, y, [z])
        effects['time_r2_residual'] = r2_res
        effects['time_slope_controlled'] = slope_res
    
    # Sampling week effect (using all available data)
    week_data = df[['sampling_wk', flux_col]].dropna()
    if len(week_data) > 1:
        x = week_data['sampling_wk'].values
        y = week_data[flux_col].values
        slope, intercept, r2, y_pred = simple_linear_regression(x, y)
        effects['week_r2'] = r2
        effects['week_corr'] = np.corrcoef(x, y)[0,1]
        effects['week_slope'] = slope
    
    # Crop effect (controlling for sampling week)
    if 'crop' in df.columns:
        crop_data = df[['crop', flux_col, 'sampling_wk']].dropna()
        if len(crop_data) > 1:
            # Simple ANOVA-like calculation (not controlling for week)
            overall_mean = crop_data[flux_col].mean()
            total_ss = np.sum((crop_data[flux_col] - overall_mean) ** 2)
            
            between_ss = 0
            for crop in crop_data['crop'].unique():
                crop_subset = crop_data[crop_data['crop'] == crop]
                if len(crop_subset) > 0:
                    crop_mean = crop_subset[flux_col].mean()
                    between_ss += len(crop_subset) * (crop_mean - overall_mean) ** 2
            
            effects['crop_r2_raw'] = between_ss / total_ss if total_ss > 0 else 0
    
    return effects

# Calculate controlled effect sizes
effects = calculate_controlled_effects(df, flux_col)
print("Controlled effect sizes calculated successfully!")
```

## Statistical Summary with Controls

```{python stats-summary}
def print_controlled_statistical_summary(df, flux_col, effects, confounding_stats):
    """Print comprehensive statistical summary with controls"""
    print("=" * 80)
    print("CONTROLLED STATISTICAL ANALYSIS SUMMARY")
    print("=" * 80)
    
    print(f"\nSample Size: {len(df)} observations")
    print(f"CO2 Flux Range: {df[flux_col].min():.3f} to {df[flux_col].max():.3f}")
    print(f"Average CO2 Flux: {df[flux_col].mean():.3f} ± {df[flux_col].std():.3f}")
    print(f"Sampling Weeks: {df['sampling_wk'].min()} to {df['sampling_wk'].max()}")
    
    print("\nCONFOUNDING ASSESSMENT:")
    print("-" * 40)
    print(f"Sealed Time ↔ Sampling Week correlation: r = {confounding_stats['time_wk_corr']:.3f}")
    print(f"Flux ↔ Sampling Week correlation: r = {confounding_stats['flux_wk_corr']:.3f}")
    
    if abs(confounding_stats['time_wk_corr']) > 0.5:
        print("⚠️  HIGH confounding between sealed time and sampling week!")
    elif abs(confounding_stats['time_wk_corr']) > 0.3:
        print("⚠️  Moderate confounding between sealed time and sampling week")
    else:
        print("✅ Low confounding between sealed time and sampling week")
    
    print("\nEFFECT SIZES: RAW vs CONTROLLED FOR SAMPLING WEEK")
    print("-" * 60)
    
    # Moisture effects
    moisture_raw = effects.get('moisture_r2_raw', 0)
    moisture_controlled = effects.get('moisture_r2_controlled', 0)
    print(f"📊 MOISTURE EFFECT:")
    print(f"   Raw R²: {moisture_raw:.3f} ({moisture_raw*100:.1f}% of variance)")
    print(f"   Controlled R²: {moisture_controlled:.3f} ({moisture_controlled*100:.1f}% of variance)")
    change = moisture_controlled - moisture_raw
    print(f"   Change: {change:+.3f} ({'strengthened' if change > 0 else 'weakened'})")
    
    # Sealed time effects  
    time_raw = effects.get('time_r2_raw', 0)
    time_controlled = effects.get('time_r2_controlled', 0)
    print(f"\n⏱️  SEALED TIME EFFECT:")
    print(f"   Raw R²: {time_raw:.3f} ({time_raw*100:.1f}% of variance)")
    print(f"   Controlled R²: {time_controlled:.3f} ({time_controlled*100:.1f}% of variance)")
    change = time_controlled - time_raw
    print(f"   Change: {change:+.3f} ({'strengthened' if change > 0 else 'weakened'})")
    
    if time_controlled < time_raw * 0.5:
        print("   🎯 MAJOR REDUCTION: Sealed time effect was largely due to temporal trend!")
    elif time_controlled < time_raw * 0.8:
        print("   ⚠️  Substantial reduction: Some sealed time effect was temporal confounding")
    else:
        print("   ✅ Effect remains strong after controlling for temporal trends")
    
    # Sampling week effect
    week_effect = effects.get('week_r2', 0)
    print(f"\n📅 SAMPLING WEEK EFFECT:")
    print(f"   R²: {week_effect:.3f} ({week_effect*100:.1f}% of variance)")
    
    # Ranking after controls
    controlled_effects = {
        'Moisture (controlled)': moisture_controlled,
        'Sealed Time (controlled)': time_controlled,
        'Sampling Week': week_effect,
        'Crop Type': effects.get('crop_r2_raw', 0)
    }
    
    print(f"\nRANKING AFTER CONTROLLING FOR TEMPORAL TRENDS:")
    print("-" * 50)
    sorted_controlled = sorted(controlled_effects.items(), key=lambda x: x[1], reverse=True)
    
    for i, (factor, r2) in enumerate(sorted_controlled):
        rank = "🥇" if i == 0 else "🥈" if i == 1 else "🥉" if i == 2 else f"{i+1}."
        print(f"{rank} {factor:25}: R² = {r2:.3f} ({r2*100:.1f}% of variance)")

# Print the controlled statistical summary
print_controlled_statistical_summary(df, flux_col, effects, confounding_stats)
```

## Key Questions with Temporal Controls

```{python questions}
def answer_controlled_questions(effects):
    """Answer the main research questions with temporal controls"""
    print("\n" + "=" * 80)
    print("ANSWERS TO YOUR KEY QUESTIONS (CONTROLLING FOR TEMPORAL TRENDS):")
    print("=" * 80)
    
    moisture_controlled = effects.get('moisture_r2_controlled', 0)
    time_controlled = effects.get('time_r2_controlled', 0)
    week_effect = effects.get('week_r2', 0)
    
    # Question 1: Which has larger effect - moisture or time? (controlled)
    print("1. MOISTURE vs SEALED TIME (after controlling for sampling week):")
    if moisture_controlled > time_controlled:
        print(f"   🏆 MOISTURE has the larger TRUE effect:")
        print(f"      - Moisture (controlled): {moisture_controlled*100:.1f}% of variance")
        print(f"      - Sealed Time (controlled): {time_controlled*100:.1f}% of variance")
    else:
        print(f"   🏆 SEALED TIME has the larger TRUE effect:")
        print(f"      - Sealed Time (controlled): {time_controlled*100:.1f}% of variance") 
        print(f"      - Moisture (controlled): {moisture_controlled*100:.1f}% of variance")
    
    # Show the bias in raw estimates
    moisture_raw = effects.get('moisture_r2_raw', 0)
    time_raw = effects.get('time_r2_raw', 0)
    
    print(f"\n   📊 Comparison of raw vs controlled estimates:")
    print(f"      - Moisture: {moisture_raw:.3f} → {moisture_controlled:.3f} (Δ = {moisture_controlled-moisture_raw:+.3f})")
    print(f"      - Sealed Time: {time_raw:.3f} → {time_controlled:.3f} (Δ = {time_controlled-time_raw:+.3f})")
    
    # Question 2: How much variance does temporal trend explain?
    print(f"\n2. TEMPORAL TREND IMPORTANCE:")
    print(f"   📅 Sampling week explains {week_effect*100:.1f}% of variance in CO2 flux")
    
    if week_effect > max(moisture_controlled, time_controlled):
        print("   🎯 TEMPORAL TRENDS are the strongest factor!")
    elif week_effect > 0.1:
        print("   ⚠️  Temporal trends are substantial and must be considered")
    else:
        print("   ✅ Temporal trends are minimal")
    
    # Question 3: Was sealed time effect inflated by temporal confounding?
    time_bias = time_raw - time_controlled
    print(f"\n3. SEALED TIME CONFOUNDING ASSESSMENT:")
    print(f"   Apparent sealed time effect: {time_raw*100:.1f}%")
    print(f"   True sealed time effect: {time_controlled*100:.1f}%") 
    print(f"   Bias due to temporal confounding: {time_bias*100:.1f}%")
    
    if time_bias > time_raw * 0.5:
        print("   🚨 MAJOR BIAS: Most of sealed time effect was temporal confounding!")
    elif time_bias > time_raw * 0.2:
        print("   ⚠️  Substantial bias: Sealed time effect was partially confounded")
    else:
        print("   ✅ Minimal bias: Sealed time effect is genuine")
    
    # Question 4: Final recommendations
    print(f"\n4. FINAL RECOMMENDATIONS:")
    top_controlled_effects = [
        ('Moisture', moisture_controlled),
        ('Sealed Time', time_controlled),
        ('Temporal Trends', week_effect)
    ]
    top_controlled_effects.sort(key=lambda x: x[1], reverse=True)
    
    print(f"   🎯 Focus on: {top_controlled_effects[0][0]} (strongest true effect)")
    print(f"   📋 Always control for: Sampling week/temporal trends")
    print(f"   ⚖️  Secondary factor: {top_controlled_effects[1][0]}")

# Answer the controlled research questions
answer_controlled_questions(effects)
```

## Visualization: Temporal Trends

```{python trends}
def plot_temporal_trends(df, flux_col):
    """Plot how variables change over sampling weeks"""
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # CO2 flux over time
    axes[0,0].scatter(df['sampling_wk'], df[flux_col], alpha=0.6)
    z = np.polyfit(df['sampling_wk'], df[flux_col], 1)
    p = np.poly1d(z)
    x_line = np.linspace(df['sampling_wk'].min(), df['sampling_wk'].max(), 100)
    axes[0,0].plot(x_line, p(x_line), "r--", alpha=0.8)
    axes[0,0].set_xlabel('Sampling Week')
    axes[0,0].set_ylabel('CO2 Flux')
    axes[0,0].set_title('CO2 Flux Over Time')
    axes[0,0].grid(True, alpha=0.3)
    
    # Sealed time over sampling weeks
    axes[0,1].scatter(df['sampling_wk'], df['sealed_minutes'], alpha=0.6)
    z = np.polyfit(df['sampling_wk'], df['sealed_minutes'], 1)
    p = np.poly1d(z)
    axes[0,1].plot(x_line, p(x_line), "r--", alpha=0.8)
    axes[0,1].set_xlabel('Sampling Week')
    axes[0,1].set_ylabel('Sealed Time (minutes)')
    axes[0,1].set_title('Sealed Time Over Sampling Weeks')
    axes[0,1].grid(True, alpha=0.3)
    
    # Moisture over sampling weeks
    axes[1,0].scatter(df['sampling_wk'], df['moisture_kpa'], alpha=0.6)
    z = np.polyfit(df['sampling_wk'], df['moisture_kpa'], 1)
    p = np.poly1d(z)
    axes[1,0].plot(x_line, p(x_line), "r--", alpha=0.8)
    axes[1,0].set_xlabel('Sampling Week')
    axes[1,0].set_ylabel('Moisture (kPa)')
    axes[1,0].set_title('Moisture Over Sampling Weeks')
    axes[1,0].grid(True, alpha=0.3)
    
    # Correlations heatmap
    corr_data = df[['sampling_wk', 'sealed_minutes', 'moisture_kpa', flux_col]].corr()
    im = axes[1,1].imshow(corr_data, cmap='RdBu', aspect='auto', vmin=-1, vmax=1)
    axes[1,1].set_xticks(range(len(corr_data.columns)))
    axes[1,1].set_yticks(range(len(corr_data.columns)))
    axes[1,1].set_xticklabels(['Week', 'Time', 'Moisture', 'Flux'], rotation=45)
    axes[1,1].set_yticklabels(['Week', 'Time', 'Moisture', 'Flux'])
    axes[1,1].set_title('Correlation Matrix')
    
    # Add correlation values to heatmap
    for i in range(len(corr_data.columns)):
        for j in range(len(corr_data.columns)):
            axes[1,1].text(j, i, f'{corr_data.iloc[i,j]:.2f}', 
                          ha='center', va='center', color='white' if abs(corr_data.iloc[i,j]) > 0.5 else 'black')
    
    plt.tight_layout()
    
    import os
    plt.savefig(os.path.join(output_folder, "temporal_trends.png"))
    plt.show()
    plt.close()

plot_temporal_trends(df, flux_col)
```

## Controlled Effect Visualizations

```{python effects-controlled}
def plot_controlled_effects(df, flux_col, effects):
    """Plot raw vs controlled effects"""
    
    # Before and after comparison
    fig, axes = plt.subplots(1, 3, figsize=(18, 6))
    
    # Moisture: raw vs controlled
    moisture_raw = effects.get('moisture_r2_raw', 0)
    moisture_controlled = effects.get('moisture_r2_controlled', 0)
    
    categories = ['Raw Effect', 'Controlled\n(for sampling week)']
    moisture_values = [moisture_raw, moisture_controlled]
    
    bars1 = axes[0].bar(categories, moisture_values, color=['lightblue', 'darkblue'], alpha=0.7)
    axes[0].set_ylabel('R² (Variance Explained)')
    axes[0].set_title('Moisture Effect: Raw vs Controlled')
    axes[0].set_ylim(0, max(moisture_values) * 1.2 if max(moisture_values) > 0 else 1)
    
    for bar, value in zip(bars1, moisture_values):
        height = bar.get_height()
        axes[0].text(bar.get_x() + bar.get_width()/2., height + 0.01,
                f'{value:.3f}', ha='center', va='bottom')
    
    # Sealed time: raw vs controlled
    time_raw = effects.get('time_r2_raw', 0)
    time_controlled = effects.get('time_r2_controlled', 0)
    
    time_values = [time_raw, time_controlled]
    
    bars2 = axes[1].bar(categories, time_values, color=['lightcoral', 'darkred'], alpha=0.7)
    axes[1].set_ylabel('R² (Variance Explained)')
    axes[1].set_title('Sealed Time Effect: Raw vs Controlled')
    axes[1].set_ylim(0, max(time_values) * 1.2 if max(time_values) > 0 else 1)
    
    for bar, value in zip(bars2, time_values):
        height = bar.get_height()
        axes[1].text(bar.get_x() + bar.get_width()/2., height + 0.01,
                f'{value:.3f}', ha='center', va='bottom')
    
    # All effects comparison
    effect_names = ['Moisture\n(controlled)', 'Sealed Time\n(controlled)', 'Sampling\nWeek', 'Crop Type\n(raw)']
    effect_values = [
        moisture_controlled,
        time_controlled,
        effects.get('week_r2', 0),
        effects.get('crop_r2_raw', 0)
    ]
    
    colors = ['blue', 'red', 'green', 'orange']
    bars3 = axes[2].bar(effect_names, effect_values, color=colors, alpha=0.7)
    axes[2].set_ylabel('R² (Variance Explained)')
    axes[2].set_title('Final Effect Size Comparison')
    axes[2].set_ylim(0, max(effect_values) * 1.2 if max(effect_values) > 0 else 1)
    
    for bar, value in zip(bars3, effect_values):
        height = bar.get_height()
        axes[2].text(bar.get_x() + bar.get_width()/2., height + 0.01,
                f'{value:.3f}', ha='center', va='bottom', rotation=0)
    
    plt.tight_layout()
        
    import os
    plt.savefig(os.path.join(output_folder, "controlled_effects.png"))
    plt.show()
    plt.close()
```

## Residual Plots

```{python residual-plots}
def plot_residual_analysis(df, flux_col, effects):
    """Plot residual analysis to check model assumptions"""
    # This function needs to be implemented
    print("Residual analysis function placeholder")
```

## Weekly Breakdown Analysis

```{python weekly-breakdown}
def analyze_by_sampling_week(df, flux_col):
    """Analyze effects within each sampling week"""
    print("=" * 60)
    print("WITHIN-WEEK ANALYSIS")
    print("=" * 60)
    print("Analyzing moisture and sealed time effects within each sampling week...")
    print("This removes between-week confounding completely.\n")
    
    weeks = sorted(df['sampling_wk'].unique())
    within_week_effects = []
    
    for week in weeks:
        week_data = df[df['sampling_wk'] == week]
        if len(week_data) < 3:  # Need minimum observations
            continue
            
        week_effects = {'week': week, 'n': len(week_data)}
        
        # Moisture effect within this week
        if len(week_data[['moisture_kpa', flux_col]].dropna()) > 1:
            moisture_clean = week_data[['moisture_kpa', flux_col]].dropna()
            if len(moisture_clean) > 1 and moisture_clean['moisture_kpa'].std() > 0:
                corr = np.corrcoef(moisture_clean['moisture_kpa'], moisture_clean[flux_col])[0,1]
                week_effects['moisture_corr'] = corr
                week_effects['moisture_r2'] = corr**2
            else:
                week_effects['moisture_corr'] = 0
                week_effects['moisture_r2'] = 0
        
        # Sealed time effect within this week  
        if len(week_data[['sealed_minutes', flux_col]].dropna()) > 1:
            time_clean = week_data[['sealed_minutes', flux_col]].dropna()
            if len(time_clean) > 1 and time_clean['sealed_minutes'].std() > 0:
                corr = np.corrcoef(time_clean['sealed_minutes'], time_clean[flux_col])[0,1]
                week_effects['time_corr'] = corr
                week_effects['time_r2'] = corr**2
            else:
                week_effects['time_corr'] = 0
                week_effects['time_r2'] = 0
        
        # Summary stats for this week
        week_effects['mean_flux'] = week_data[flux_col].mean()
        week_effects['mean_moisture'] = week_data['moisture_kpa'].mean()
        week_effects['mean_time'] = week_data['sealed_minutes'].mean()
        
        within_week_effects.append(week_effects)
    
    # Print results
    print(f"{'Week':<6} {'n':<4} {'Flux':<8} {'Moisture r':<12} {'Time r':<10} {'Notes':<20}")
    print("-" * 70)
    
    moisture_rs = []
    time_rs = []
    
    for week_effect in within_week_effects:
        moisture_r = week_effect.get('moisture_corr', 0)
        time_r = week_effect.get('time_corr', 0)
        
        moisture_rs.append(moisture_r)
        time_rs.append(time_r)
        
        notes = []
        if abs(moisture_r) > 0.3:
            notes.append("Strong moisture")
        if abs(time_r) > 0.3:
            notes.append("Strong time")
        if not notes:
            notes.append("Weak effects")
            
        print(f"{week_effect['week']:<6} {week_effect['n']:<4} "
              f"{week_effect['mean_flux']:<8.2f} {moisture_r:<12.3f} "
              f"{time_r:<10.3f} {', '.join(notes)}")
    
    # Overall within-week summary
    if moisture_rs and time_rs:
        avg_moisture_r = np.mean([abs(r) for r in moisture_rs if not np.isnan(r)])
        avg_time_r = np.mean([abs(r) for r in time_rs if not np.isnan(r)])
        
        print(f"\nAVERAGE WITHIN-WEEK EFFECTS:")
        print(f"Average |moisture correlation|: {avg_moisture_r:.3f}")
        print(f"Average |sealed time correlation|: {avg_time_r:.3f}")
        
        if avg_moisture_r > avg_time_r:
            print("🎯 Within-week analysis confirms: MOISTURE has stronger effect")
        else:
            print("🎯 Within-week analysis confirms: SEALED TIME has stronger effect")
    
    return within_week_effects

# Perform within-week analysis
within_week_results = analyze_by_sampling_week(df, flux_col)
```

## Summary Tables

```{python summary-tables}
def create_comprehensive_summary_table(effects, confounding_stats):
    """Create comprehensive summary table comparing raw vs controlled effects"""
    
    summary_data = {
        'Factor': [
            'Moisture (soil water potential)', 
            'Sealed Time (chamber closure)', 
            'Sampling Week (temporal trend)',
            'Combined Moisture + Time',
            'Combined with Week Trend'
        ],
        'Raw R² (uncorrected)': [
            f"{effects.get('moisture_r2_raw', 0):.3f}",
            f"{effects.get('time_r2_raw', 0):.3f}",
            f"{effects.get('week_r2', 0):.3f}",
            f"{effects.get('combined_controlled_r2', 0):.3f}",
            f"{effects.get('combined_with_week_r2', 0):.3f}"
        ],
        'Controlled R² (for temporal trends)': [
            f"{effects.get('moisture_r2_controlled', 0):.3f}",
            f"{effects.get('time_r2_controlled', 0):.3f}",
            "N/A (reference)",
            f"{effects.get('combined_controlled_r2', 0):.3f}",
            "N/A"
        ],
        'Bias Assessment': [
            "Minimal bias" if abs(effects.get('moisture_r2_raw', 0) - effects.get('moisture_r2_controlled', 0)) < 0.05 else "Some bias",
            "Major bias" if effects.get('time_r2_raw', 0) - effects.get('time_r2_controlled', 0) > 0.1 else "Moderate bias" if effects.get('time_r2_raw', 0) - effects.get('time_r2_controlled', 0) > 0.05 else "Minimal bias",
            "N/A",
            "Reduced when controlling for trends",
            "Higher due to temporal autocorrelation"
        ]
    }
    
    summary_df = pd.DataFrame(summary_data)
    print("\nCOMPREHENSIVE SUMMARY TABLE:")
    print("=" * 100)
    print(summary_df.to_string(index=False))
    
    # Key findings summary
    print(f"\n🔍 KEY FINDINGS:")
    print(f"{'='*50}")
    
    time_bias = effects.get('time_r2_raw', 0) - effects.get('time_r2_controlled', 0)
    moisture_bias = effects.get('moisture_r2_raw', 0) - effects.get('moisture_r2_controlled', 0)
    
    print(f"1. Temporal confounding in sealed time: {time_bias:.3f} R² units")
    print(f"2. Temporal confounding in moisture: {moisture_bias:.3f} R² units")
    print(f"3. Time-week correlation: r = {confounding_stats['time_wk_corr']:.3f}")
    print(f"4. Flux temporal trend: r = {confounding_stats['flux_wk_corr']:.3f}")
    
    # Recommendations
    print(f"\n📋 RECOMMENDATIONS:")
    print(f"{'='*30}")
    
    if time_bias > 0.1:
        print("⚠️  CRITICAL: Always control for sampling week when analyzing sealed time")
    if effects.get('time_r2_controlled', 0) < 0.05:
        print("🎯 Sealed time effect appears largely artifactual (temporal confounding)")
    if effects.get('moisture_r2_controlled', 0) > effects.get('time_r2_controlled', 0):
        print("🌊 Focus research efforts on soil moisture effects")
    if effects.get('week_r2', 0) > 0.2:
        print("📅 Strong temporal trends - investigate seasonal/environmental drivers")
    
    return summary_df

# Create comprehensive summary
final_summary = create_comprehensive_summary_table(effects, confounding_stats)
```

## Final Diagnostic Plots

```{python final-diagnostic-plots}

def create_diagnostic_plots(df, flux_col, effects):
    """Create diagnostic plots to visualize the confounding issue"""
    
    # Check if we have enough data for diagnostic plots
    if len(df) < 10:
        print("Warning: Insufficient data for diagnostic plots")
        return
    
    try:
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        
        # Row 1: Raw relationships
        # Raw flux vs sealed time
        if df['sealed_minutes'].std() > 0 and df[flux_col].std() > 0:
            axes[0,0].scatter(df['sealed_minutes'], df[flux_col], alpha=0.6, color='red')
            try:
                z = np.polyfit(df['sealed_minutes'], df[flux_col], 1)
                p = np.poly1d(z)
                x_line = np.linspace(df['sealed_minutes'].min(), df['sealed_minutes'].max(), 100)
                axes[0,0].plot(x_line, p(x_line), "k--", alpha=0.8)
            except np.linalg.LinAlgError:
                print("Warning: Could not fit trend line for sealed time vs flux")
        axes[0,0].set_xlabel('Sealed Time (minutes)')
        axes[0,0].set_ylabel('CO2 Flux')
        axes[0,0].set_title(f'RAW: Flux vs Sealed Time\nR² = {effects.get("time_r2_raw", 0):.3f}')
        axes[0,0].grid(True, alpha=0.3)
        
        # Raw flux vs moisture (only for data with moisture)
        moisture_data = df.dropna(subset=['moisture_kpa'])
        if len(moisture_data) > 5 and moisture_data['moisture_kpa'].std() > 0:
            axes[0,1].scatter(moisture_data['moisture_kpa'], moisture_data[flux_col], alpha=0.6, color='blue')
            try:
                z = np.polyfit(moisture_data['moisture_kpa'], moisture_data[flux_col], 1)
                p = np.poly1d(z)
                x_line = np.linspace(moisture_data['moisture_kpa'].min(), moisture_data['moisture_kpa'].max(), 100)
                axes[0,1].plot(x_line, p(x_line), "k--", alpha=0.8)
            except np.linalg.LinAlgError:
                print("Warning: Could not fit trend line for moisture vs flux")
        else:
            axes[0,1].text(0.5, 0.5, 'Insufficient\nMoisture Data', ha='center', va='center', transform=axes[0,1].transAxes)
        
        axes[0,1].set_xlabel('Moisture (kPa)')
        axes[0,1].set_ylabel('CO2 Flux')
        axes[0,1].set_title(f'RAW: Flux vs Moisture\nR² = {effects.get("moisture_r2_raw", 0):.3f}')
        axes[0,1].grid(True, alpha=0.3)
        
        # Confounding relationship: sealed time vs week
        if df['sampling_wk'].std() > 0 and df['sealed_minutes'].std() > 0:
            axes[0,2].scatter(df['sampling_wk'], df['sealed_minutes'], alpha=0.6, color='orange')
            try:
                z = np.polyfit(df['sampling_wk'], df['sealed_minutes'], 1)
                p = np.poly1d(z)
                x_line = np.linspace(df['sampling_wk'].min(), df['sampling_wk'].max(), 100)
                axes[0,2].plot(x_line, p(x_line), "k--", alpha=0.8)
            except np.linalg.LinAlgError:
                print("Warning: Could not fit trend line for time vs week")
        axes[0,2].set_xlabel('Sampling Week')
        axes[0,2].set_ylabel('Sealed Time (minutes)')
        axes[0,2].set_title(f'CONFOUNDING: Time vs Week\nr = {effects.get("time_wk_corr", 0):.3f}')
        axes[0,2].grid(True, alpha=0.3)
        
        # Row 2: Controlled relationships (residuals after removing week effects)
        week_slope_flux = effects.get('week_slope', 0)
        week_mean = df['sampling_wk'].mean()
        flux_detrended = df[flux_col] - (week_slope_flux * (df['sampling_wk'] - week_mean))
        
        # Calculate sealed time residuals (remove week trend from sealed time too)
        if df['sampling_wk'].std() > 0 and df['sealed_minutes'].std() > 0:
            try:
                sealed_time_week_slope = np.polyfit(df['sampling_wk'], df['sealed_minutes'], 1)[0]
                sealed_time_detrended = df['sealed_minutes'] - (sealed_time_week_slope * (df['sampling_wk'] - week_mean))
            except np.linalg.LinAlgError:
                sealed_time_detrended = df['sealed_minutes'] - df['sealed_minutes'].mean()
        else:
            sealed_time_detrended = df['sealed_minutes'] - df['sealed_minutes'].mean()
        
        # Controlled flux vs sealed time residuals
        axes[1,0].scatter(sealed_time_detrended, flux_detrended, alpha=0.6, color='red')
        if np.std(sealed_time_detrended) > 1e-10:
            try:
                z = np.polyfit(sealed_time_detrended, flux_detrended, 1)
                p = np.poly1d(z)
                x_line = np.linspace(sealed_time_detrended.min(), sealed_time_detrended.max(), 100)
                axes[1,0].plot(x_line, p(x_line), "k--", alpha=0.8)
            except np.linalg.LinAlgError:
                print("Warning: Could not fit trend line for controlled time vs flux")
        axes[1,0].set_xlabel('Sealed Time (residuals)')
        axes[1,0].set_ylabel('CO2 Flux (detrended)')
        axes[1,0].set_title(f'CONTROLLED: Flux vs Sealed Time\nR² = {effects.get("time_r2_controlled", 0):.3f}')
        axes[1,0].grid(True, alpha=0.3)
        
        # Calculate moisture residuals (only for data with moisture)
        moisture_complete = df.dropna(subset=['moisture_kpa'])
        if len(moisture_complete) > 5:
            try:
                moisture_week_slope = np.polyfit(moisture_complete['sampling_wk'], moisture_complete['moisture_kpa'], 1)[0]
                moisture_detrended = moisture_complete['moisture_kpa'] - (moisture_week_slope * (moisture_complete['sampling_wk'] - week_mean))
                flux_detrended_moisture = moisture_complete[flux_col] - (week_slope_flux * (moisture_complete['sampling_wk'] - week_mean))
                
                axes[1,1].scatter(moisture_detrended, flux_detrended_moisture, alpha=0.6, color='blue')
                if np.std(moisture_detrended) > 1e-10:
                    try:
                        z = np.polyfit(moisture_detrended, flux_detrended_moisture, 1)
                        p = np.poly1d(z)
                        x_line = np.linspace(moisture_detrended.min(), moisture_detrended.max(), 100)
                        axes[1,1].plot(x_line, p(x_line), "k--", alpha=0.8)
                    except np.linalg.LinAlgError:
                        print("Warning: Could not fit trend line for controlled moisture vs flux")
            except np.linalg.LinAlgError:
                axes[1,1].text(0.5, 0.5, 'Insufficient\nMoisture Data\nfor Detrending', ha='center', va='center', transform=axes[1,1].transAxes)
        else:
            axes[1,1].text(0.5, 0.5, 'Insufficient\nMoisture Data', ha='center', va='center', transform=axes[1,1].transAxes)
        axes[1,1].set_xlabel('Moisture (residuals)')
        axes[1,1].set_ylabel('CO2 Flux (detrended)')
        axes[1,1].set_title(f'CONTROLLED: Flux vs Moisture\nR² = {effects.get("moisture_r2_controlled", 0):.3f}')
        axes[1,1].grid(True, alpha=0.3)
        
        # Effect size comparison
        effect_names = ['Sealed\nTime\n(Raw)', 'Sealed\nTime\n(Controlled)', 'Moisture\n(Raw)', 'Moisture\n(Controlled)', 'Sampling\nWeek']
        effect_values = [
            effects.get('time_r2_raw', 0),
            effects.get('time_r2_controlled', 0),
            effects.get('moisture_r2_raw', 0), 
            effects.get('moisture_r2_controlled', 0),
            effects.get('week_r2', 0)
        ]
        colors = ['lightcoral', 'darkred', 'lightblue', 'darkblue', 'green']
        
        bars = axes[1,2].bar(effect_names, effect_values, color=colors, alpha=0.7)
        axes[1,2].set_ylabel('R² (Variance Explained)')
        axes[1,2].set_title('Effect Size Comparison:\nRaw vs Controlled')
        axes[1,2].set_ylim(0, max(effect_values) * 1.2 if max(effect_values) > 0 else 1)
        
        for bar, value in zip(bars, effect_values):
            height = bar.get_height()
            axes[1,2].text(bar.get_x() + bar.get_width()/2., height + 0.005,
                    f'{value:.3f}', ha='center', va='bottom', fontsize=8)
        
        axes[1,2].tick_params(axis='x', labelsize=8)
        axes[1,2].grid(True, alpha=0.3)
        
        plt.tight_layout()
        import os
        plt.savefig(os.path.join(output_folder, "diagnostic_plots.png"))
        plt.show()
        plt.close()
        
        # Print interpretation
        print("🔍 DIAGNOSTIC PLOT INTERPRETATION:")
        print("-" * 50)
        print("TOP ROW: Shows the raw relationships and the confounding problem")
        print("BOTTOM ROW: Shows relationships after removing temporal trends")
        print("")
        
        time_reduction = effects.get('time_r2_raw', 0) - effects.get('time_r2_controlled', 0)
        moisture_reduction = effects.get('moisture_r2_raw', 0) - effects.get('moisture_r2_controlled', 0)
        
        if time_reduction > 0.1:
            print("🎯 SEALED TIME: Large reduction confirms substantial temporal confounding")
        elif time_reduction > 0.05:
            print("⚠️  SEALED TIME: Moderate reduction suggests some temporal confounding")  
        else:
            print("✅ SEALED TIME: Minimal reduction suggests genuine effect")
            
        if moisture_reduction > 0.05:
            print("🌊 MOISTURE: Some temporal confounding detected")
        else:
            print("✅ MOISTURE: Effect appears independent of temporal trends")
            
    except Exception as e:
        print(f"Error creating diagnostic plots: {str(e)}")
        print("Skipping diagnostic plots due to numerical issues")
        return

create_diagnostic_plots(df, flux_col, effects)
```

## Export Controlled Results

```{python export-controlled-results}
def export_controlled_results(df, effects, confounding_stats, flux_col):
    """Export comprehensive controlled analysis results"""
    
    results_summary = {
        'analysis_type': 'Controlled for Sampling Week',
        'analysis_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),
        'sample_size': len(df),
        'flux_column': flux_col,
        'sampling_week_range': f"{df['sampling_wk'].min()} to {df['sampling_wk'].max()}",
        
        # Confounding assessment
        'time_week_correlation': confounding_stats['time_wk_corr'],
        'flux_week_correlation': confounding_stats['flux_wk_corr'],
        'moisture_week_correlation': confounding_stats['moisture_wk_corr'],
        
        # Raw effects
        'moisture_r2_raw': effects.get('moisture_r2_raw', 0),
        'time_r2_raw': effects.get('time_r2_raw', 0),
        'week_r2': effects.get('week_r2', 0),
        
        # Controlled effects  
        'moisture_r2_controlled': effects.get('moisture_r2_controlled', 0),
        'time_r2_controlled': effects.get('time_r2_controlled', 0),
        
        # Bias quantification
        'time_bias': effects.get('time_r2_raw', 0) - effects.get('time_r2_controlled', 0),
        'moisture_bias': effects.get('moisture_r2_raw', 0) - effects.get('moisture_r2_controlled', 0),
        
        # Final ranking
        'strongest_controlled_effect': 'moisture' if effects.get('moisture_r2_controlled', 0) > effects.get('time_r2_controlled', 0) else 'sealed_time',
        'temporal_trend_importance': 'high' if effects.get('week_r2', 0) > 0.2 else 'moderate' if effects.get('week_r2', 0) > 0.1 else 'low'
    }
    
    print("CONTROLLED ANALYSIS RESULTS SUMMARY:")
    print("=" * 60)
    for key, value in results_summary.items():
        if isinstance(value, float):
            print(f"{key}: {value:.3f}")
        else:
            print(f"{key}: {value}")
    
    print(f"\n🎯 FINAL ANSWER TO YOUR ORIGINAL QUESTION:")
    print(f"After controlling for temporal trends (sampling week):")
    
    moisture_controlled = effects.get('moisture_r2_controlled', 0)
    time_controlled = effects.get('time_r2_controlled', 0)
    
    if moisture_controlled > time_controlled:
        advantage = (moisture_controlled - time_controlled) / time_controlled * 100 if time_controlled > 0 else float('inf')
        print(f"MOISTURE has the larger TRUE effect ({moisture_controlled:.3f} vs {time_controlled:.3f})")
        if advantage > 100:
            print(f"Moisture effect is >2x stronger than sealed time effect")
        else:
            print(f"Moisture effect is {advantage:.0f}% stronger than sealed time effect")
    else:
        advantage = (time_controlled - moisture_controlled) / moisture_controlled * 100 if moisture_controlled > 0 else float('inf')
        print(f"SEALED TIME has the larger TRUE effect ({time_controlled:.3f} vs {moisture_controlled:.3f})")
        if advantage > 100:
            print(f"Sealed time effect is >2x stronger than moisture effect")
        else:
            print(f"Sealed time effect is {advantage:.0f}% stronger than moisture effect")
    
    return results_summary

# Export the controlled results
controlled_results = export_controlled_results(df, effects, confounding_stats, flux_col)
```

## Corrected Flux Data for Crop Analysis

```{python corrected-flux}
def correct_flux_for_confounders(df, flux_col, effects):
    """Correct CO2 flux data by removing sealed time effects (and moisture when available)"""
    
    # Create a copy of the dataframe
    df_corrected = df.copy()
    
    # Get the raw flux values
    flux_raw = df_corrected[flux_col].copy()
    
    # Start with raw flux
    flux_corrected = flux_raw.copy()
    
    # Remove sealed time effect for ALL data (using controlled slope)
    time_slope = effects.get('time_slope_controlled', 0)
    time_mean = df_corrected['sealed_minutes'].mean()
    flux_corrected = flux_corrected - (time_slope * (df_corrected['sealed_minutes'] - time_mean))
    
    # Remove moisture effect ONLY where moisture data is available
    moisture_slope = effects.get('moisture_slope_controlled', 0)
    has_moisture = ~df_corrected['moisture_kpa'].isna()
    
    if has_moisture.sum() > 0 and moisture_slope != 0:
        moisture_mean = df_corrected.loc[has_moisture, 'moisture_kpa'].mean()
        # Apply moisture correction only to rows with moisture data
        flux_corrected.loc[has_moisture] = (
            flux_corrected.loc[has_moisture] - 
            (moisture_slope * (df_corrected.loc[has_moisture, 'moisture_kpa'] - moisture_mean))
        )
    
    # Add corrected flux as new column
    df_corrected['flux_corrected'] = flux_corrected
    
    # Create a flag for which corrections were applied
    df_corrected['time_corrected'] = True
    df_corrected['moisture_corrected'] = has_moisture
    
    print("Flux corrections applied:")
    print(f"Original flux range: {flux_raw.min():.3f} to {flux_raw.max():.3f}")
    print(f"Corrected flux range: {flux_corrected.min():.3f} to {flux_corrected.max():.3f}")
    print(f"Time correction applied to: {len(df_corrected)} observations")
    print(f"Moisture correction applied to: {has_moisture.sum()} observations")
    print(f"Only time correction (no moisture): {(~has_moisture).sum()} observations")
    
    # Show which weeks/crops have missing moisture data
    missing_moisture = df_corrected[~has_moisture]
    if len(missing_moisture) > 0:
        print("\nObservations with missing moisture data (time-only correction):")
        missing_summary = missing_moisture.groupby(['sampling_wk', 'crop']).size()
        for (week, crop), count in missing_summary.items():
            print(f"  Week {week}, {crop}: {count} observations")
    
    return df_corrected

def visualize_crop_effects(df_corrected, flux_col):
    """Visualize crop effects before and after correction"""
    
    if 'crop' not in df_corrected.columns:
        print("Warning: 'crop' column not found. Cannot analyze crop effects.")
        return
    
    # Define crop colors
    crop_colors = {'noPlant': '#9F29FF', 'wheat': '#98C65D', 'rice': '#FC9D33', 'soy': '#FE318E'}
    
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    
    # Raw flux by crop
    crops = df_corrected['crop'].unique()
    
    for crop in crops:
        crop_data = df_corrected[df_corrected['crop'] == crop]
        color = crop_colors.get(crop, '#000000')  # Default to black if crop not in color dict
        axes[0,0].scatter(crop_data['sampling_wk'], crop_data[flux_col], 
                         alpha=0.6, label=crop, color=color)
    
    axes[0,0].set_xlabel('Sampling Week')
    axes[0,0].set_ylabel('Raw CO2 Flux')
    axes[0,0].set_title('Raw CO2 Flux by Crop Over Time')
    axes[0,0].legend()
    axes[0,0].grid(True, alpha=0.3)
    
    # Corrected flux by crop
    for crop in crops:
        crop_data = df_corrected[df_corrected['crop'] == crop]
        color = crop_colors.get(crop, '#000000')
        axes[0,1].scatter(crop_data['sampling_wk'], crop_data['flux_corrected'], 
                         alpha=0.6, label=crop, color=color)
    
    axes[0,1].set_xlabel('Sampling Week')
    axes[0,1].set_ylabel('Corrected CO2 Flux (moisture & time effects removed)')
    axes[0,1].set_title('Corrected CO2 Flux by Crop Over Time')
    axes[0,1].legend()
    axes[0,1].grid(True, alpha=0.3)
    
    # Box plots - Raw flux
    crop_names = []
    raw_flux_by_crop = []
    colors_ordered = []
    for crop in crops:
        crop_data = df_corrected[df_corrected['crop'] == crop]
        if len(crop_data) > 0:
            crop_names.append(crop)
            raw_flux_by_crop.append(crop_data[flux_col].values)
            colors_ordered.append(crop_colors.get(crop, '#000000'))
    
    box1 = axes[1,0].boxplot(raw_flux_by_crop, labels=crop_names, patch_artist=True)
    for patch, color in zip(box1['boxes'], colors_ordered):
        patch.set_facecolor(color)
        patch.set_alpha(0.7)
    
    axes[1,0].set_ylabel('Raw CO2 Flux')
    axes[1,0].set_title('Raw Flux Distribution by Crop')
    axes[1,0].tick_params(axis='x', rotation=45)
    axes[1,0].grid(True, alpha=0.3)
    
    # Box plots - Corrected flux
    corrected_flux_by_crop = []
    for crop in crops:
        crop_data = df_corrected[df_corrected['crop'] == crop]
        if len(crop_data) > 0:
            corrected_flux_by_crop.append(crop_data['flux_corrected'].values)
    
    box2 = axes[1,1].boxplot(corrected_flux_by_crop, labels=crop_names, patch_artist=True)
    for patch, color in zip(box2['boxes'], colors_ordered):
        patch.set_facecolor(color)
        patch.set_alpha(0.7)
    
    axes[1,1].set_ylabel('Corrected CO2 Flux (moisture & time effects removed)')
    axes[1,1].set_title('Corrected Flux Distribution by Crop')
    axes[1,1].tick_params(axis='x', rotation=45)
    axes[1,1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    import os
    plt.savefig(os.path.join(output_folder, "crop_effects_comparison.png"))
    plt.show()
    plt.close()
    
    # Statistical comparison
    print("\nCROP EFFECT ANALYSIS:")
    print("="*50)
    
    # Calculate means and differences
    for crop in crops:
        crop_data = df_corrected[df_corrected['crop'] == crop]
        if len(crop_data) > 0:
            raw_mean = crop_data[flux_col].mean()
            corrected_mean = crop_data['flux_corrected'].mean()
            print(f"{crop}:")
            print(f"  Raw flux mean: {raw_mean:.3f}")
            print(f"  Corrected flux mean: {corrected_mean:.3f}")
            print(f"  Difference: {corrected_mean - raw_mean:.3f}")
            print()

def export_corrected_data(df_corrected, flux_col):
    """Export corrected data for further analysis"""
    
    # Create summary statistics
    summary_stats = df_corrected.groupby('crop').agg({
        flux_col: ['count', 'mean', 'std'],
        'flux_corrected': ['mean', 'std'],
        'moisture_kpa': 'mean',
        'sealed_minutes': 'mean',
        'sampling_wk': ['min', 'max']
    }).round(3)
    
    print("\nSUMMARY STATISTICS BY CROP:")
    print("="*60)
    print(summary_stats)
    
    # Export to CSV
    import os
    corrected_file = os.path.join(output_folder, "flux_data_corrected.csv")
    df_corrected.to_csv(corrected_file, index=False)
    print(f"\nCorrected data exported to: {corrected_file}")
    
    # Export summary statistics
    summary_file = os.path.join(output_folder, "crop_summary_statistics.csv")
    summary_stats.to_csv(summary_file)
    print(f"Summary statistics exported to: {summary_file}")
    
    return summary_stats

# Apply corrections and visualize
print("Correcting flux data for confounding factors...")
df_corrected = correct_flux_for_confounders(df, flux_col, effects)
visualize_crop_effects(df_corrected, flux_col)
summary_stats = export_corrected_data(df_corrected, flux_col)
```

## Corrected Flux Plot (Matching Original Style)

```{python corrected-flux-plot-styled}
def create_corrected_flux_plot_styled(df_corrected, flux_col):
    """Create a corrected flux plot matching the original pot flux plot style"""
    
    if 'crop' not in df_corrected.columns:
        print("Warning: 'crop' column not found. Cannot create plot.")
        return
    
    # Create figure for plotting (matching original style)
    fig = plt.figure(figsize=(12, 8))
    fig.suptitle(r'Intact Pots: $\mathrm{CO_2}$ Flux by Crop (Corrected for Moisture & Time Effects)', fontsize=16)

    # Get unique crops
    crops = df_corrected['crop'].unique()

    # Define colors for crops (matching original plots)
    crop_colors = {'noPlant': '#9F29FF', 'wheat': '#98C65D', 'rice': '#FC9D33', 'soy': '#FE318E'}  # purple, green, orange, pink

    # Plot corrected CO2 flux for each crop
    for crop in crops:
        # Filter data for this crop
        subset = df_corrected[df_corrected['crop'] == crop]
        
        # Calculate mean and standard error for each sampling_wk using corrected flux
        grouped = subset.groupby('sampling_wk')['flux_corrected'].agg(['mean', 'sem']).reset_index()
        
        # Use predefined color if available, otherwise use default
        color = crop_colors.get(crop, '#000000')
        
        # Plot the mean values (matching original style exactly)
        plt.errorbar(grouped['sampling_wk'], grouped['mean'], yerr=grouped['sem'],
                     marker='o', linestyle='-', label=f'{crop}', color=color, linewidth=2.5, markersize=8)

    # Labels and styling (matching original exactly)
    plt.xlabel('Sampling Week', fontsize=12)
    plt.ylabel(r'Corrected $\mathrm{CO_2}$ flux $\mathrm{(μg CO_2}$-$\mathrm{C \cdot cm}$-$\mathrm{[V/A]^{-1} \cdot minute^{-1}})$', fontsize=12)
    plt.title(r'Corrected $\mathrm{CO_2}$ flux $\mathrm{(μg CO_2}$-$\mathrm{C \cdot cm}$-$\mathrm{[V/A]^{-1} \cdot minute^{-1}})$ vs Sampling Week by Crop', fontsize=14, pad=20)
    plt.grid(True, linestyle='--', alpha=0.7)
    plt.legend(fontsize=11)

    # Add styling (matching original)
    ax = plt.gca()
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    
    # Adjust layout and save figure
    plt.tight_layout()
    import os
    plt.savefig(os.path.join(output_folder, "corrected_flux_by_crop_styled.png"), dpi=300, bbox_inches='tight')
    plt.show()
    plt.close()
    
    print("\nCorrected flux plot (styled) saved successfully!")
    
    # Print comparison of means
    print("\nCOMPARISON: Raw vs Corrected Flux Means by Crop")
    print("="*55)
    
    for crop in crops:
        crop_data = df_corrected[df_corrected['crop'] == crop]
        if len(crop_data) > 0:
            raw_mean = crop_data[flux_col].mean()
            corrected_mean = crop_data['flux_corrected'].mean()
            difference = corrected_mean - raw_mean
            percent_change = (difference / raw_mean * 100) if raw_mean != 0 else 0
            
            print(f"{crop}:")
            print(f"  Raw mean:       {raw_mean:.3f}")
            print(f"  Corrected mean: {corrected_mean:.3f}")
            print(f"  Difference:     {difference:+.3f} ({percent_change:+.1f}%)")
            print()

# Create the styled corrected flux plot
create_corrected_flux_plot_styled(df_corrected, flux_col)
```